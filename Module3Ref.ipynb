{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":64148,"databundleVersionId":7669720,"sourceType":"competition"},{"sourceId":7045515,"sourceType":"datasetVersion","datasetId":4054191},{"sourceId":7923451,"sourceType":"datasetVersion","datasetId":4633221},{"sourceId":11371,"sourceType":"modelInstanceVersion","modelInstanceId":5171}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":2365.313933,"end_time":"2024-02-27T21:18:25.620906","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-02-27T20:39:00.306973","version":"2.5.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importation\n","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\npd.set_option('display.max_colwidth', None)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2024-04-28T20:54:24.552003Z","iopub.status.idle":"2024-04-28T20:54:24.552464Z","shell.execute_reply.started":"2024-04-28T20:54:24.552233Z","shell.execute_reply":"2024-04-28T20:54:24.552253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Installation of Keras\n","metadata":{}},{"cell_type":"code","source":"# Install Keras 3 last. \n!pip install -q -U keras-nlp\n!pip install -q -U keras>=3","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2024-04-28T20:54:45.878221Z","iopub.execute_input":"2024-04-28T20:54:45.878886Z","iopub.status.idle":"2024-04-28T20:55:16.653373Z","shell.execute_reply.started":"2024-04-28T20:54:45.878849Z","shell.execute_reply":"2024-04-28T20:55:16.652411Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import sklearn\nimport pandas as pd\nimport numpy as np\nfrom wordcloud import WordCloud, STOPWORDS\nimport keras\nimport keras_nlp\nfrom IPython.display import display, Markdown\nimport matplotlib.pyplot as plt\nfrom keras_nlp.models import GemmaCausalLM\nimport re\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-04-28T20:57:04.162743Z","iopub.execute_input":"2024-04-28T20:57:04.163260Z","iopub.status.idle":"2024-04-28T20:57:17.909668Z","shell.execute_reply.started":"2024-04-28T20:57:04.163221Z","shell.execute_reply":"2024-04-28T20:57:17.908646Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-04-28 20:57:07.637576: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-28 20:57:07.637690: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-28 20:57:07.748001: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Importing OS\n","metadata":{}},{"cell_type":"code","source":"import os\nos.environ[\"KERAS_BACKEND\"] = \"jax\"  # Or \"torch\" or \"tensorflow\".\n# Avoid memory fragmentation on JAX backend.\nos.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\"1.00\"","metadata":{"execution":{"iopub.status.busy":"2024-04-28T20:58:01.896176Z","iopub.execute_input":"2024-04-28T20:58:01.897393Z","iopub.status.idle":"2024-04-28T20:58:01.901780Z","shell.execute_reply.started":"2024-04-28T20:58:01.897358Z","shell.execute_reply":"2024-04-28T20:58:01.900818Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Loading Dataset\nDataset Link: https://www.kaggle.com/datasets/hserdaraltan/1000-data-science-concepts\n\nThis dataset covers more than 1000 common data science concepts.","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/1000-data-science-concepts/data_science_concepts.csv',nrows=200)\ndata.head() # First 5 rows of the dataset","metadata":{"papermill":{"duration":0.043817,"end_time":"2024-02-27T20:39:03.856006","exception":false,"start_time":"2024-02-27T20:39:03.812189","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-28T20:58:05.754558Z","iopub.execute_input":"2024-04-28T20:58:05.755444Z","iopub.status.idle":"2024-04-28T20:58:05.796914Z","shell.execute_reply.started":"2024-04-28T20:58:05.755397Z","shell.execute_reply":"2024-04-28T20:58:05.796049Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                            Question  \\\n0  What is under-fitting and overfitting in machi...   \n1  Can you explain what a false positive and a fa...   \n2                   Clarify the concept of Phase IV.   \n3  What is semi-supervised learning described in ...   \n4  Discuss the parallelization of training in gra...   \n\n                                              Answer  \n0  Underfitting is when a model is too simple, an...  \n1  A false positive incorrectly indicates a condi...  \n2  Phase IV studies, also known as post-marketing...  \n3  Semi-supervised learning integrates both label...  \n4  Parallelizing training of a gradient boosting ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Question</th>\n      <th>Answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What is under-fitting and overfitting in machi...</td>\n      <td>Underfitting is when a model is too simple, an...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Can you explain what a false positive and a fa...</td>\n      <td>A false positive incorrectly indicates a condi...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Clarify the concept of Phase IV.</td>\n      <td>Phase IV studies, also known as post-marketing...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What is semi-supervised learning described in ...</td>\n      <td>Semi-supervised learning integrates both label...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Discuss the parallelization of training in gra...</td>\n      <td>Parallelizing training of a gradient boosting ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.tail() # Last 5 rows of the dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-28T20:58:09.281501Z","iopub.execute_input":"2024-04-28T20:58:09.281832Z","iopub.status.idle":"2024-04-28T20:58:09.293712Z","shell.execute_reply.started":"2024-04-28T20:58:09.281808Z","shell.execute_reply":"2024-04-28T20:58:09.292722Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                              Question  \\\n195  Why are activation functions required in neura...   \n196  Can you explain a bidirectional search algorithm?   \n197  Do gradient descent methods always converge to...   \n198                                 Describe word2vec.   \n199  What is the difference between a generative an...   \n\n                                                Answer  \n195  Activation functions introduce nonlinearity, e...  \n196  A bidirectional search algorithm runs two simu...  \n197  Gradient descent methods may converge to diffe...  \n198  Word2vec is a suite of models used to produce ...  \n199  Generative models learn data categories, while...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Question</th>\n      <th>Answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>195</th>\n      <td>Why are activation functions required in neura...</td>\n      <td>Activation functions introduce nonlinearity, e...</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>Can you explain a bidirectional search algorithm?</td>\n      <td>A bidirectional search algorithm runs two simu...</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>Do gradient descent methods always converge to...</td>\n      <td>Gradient descent methods may converge to diffe...</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>Describe word2vec.</td>\n      <td>Word2vec is a suite of models used to produce ...</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>What is the difference between a generative an...</td>\n      <td>Generative models learn data categories, while...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Gemma Model\n**Gemma Model** is a collection of lightweight open-source generative AI (GenAI) models developed by Google DeepMind. \n\n**Inputs and Outputs**\n* Input: Gemma models take in text strings, which can range from questions and prompts to longer documents that require summarization.\n* Output: In response, they generate text in English, offering answers, summaries, or other forms of text-based output, tailored to the input provided.\n","metadata":{"papermill":{"duration":0.007713,"end_time":"2024-02-27T20:39:44.261984","exception":false,"start_time":"2024-02-27T20:39:44.254271","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"This code snippet creates an instance of the GemmaCausalLM model and assigns it to the variable gemma_lm. It creates the model from a preset configuration named \"gemma_instruct_2b_en\".This preset specifies the architecture, hyperparameters, and other settings for the model.","metadata":{}},{"cell_type":"code","source":"#Create the model using the from_preset method\ngemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_2b_en\")\ngemma_lm.summary()","metadata":{"_kg_hide-output":true,"papermill":{"duration":55.420002,"end_time":"2024-02-27T20:40:39.689056","exception":false,"start_time":"2024-02-27T20:39:44.269054","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-28T20:58:22.225697Z","iopub.execute_input":"2024-04-28T20:58:22.226385Z","iopub.status.idle":"2024-04-28T20:59:30.688004Z","shell.execute_reply.started":"2024-04-28T20:58:22.226345Z","shell.execute_reply":"2024-04-28T20:59:30.687060Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"Attaching 'config.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'model.weights.h5' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'assets/tokenizer/vocabulary.spm' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nnormalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                   │                                             \u001b[38;5;34m256,000\u001b[0m │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                   │                                             <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,506,172,416\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"## Test Model\n","metadata":{}},{"cell_type":"code","source":"import time\nfrom memory_profiler import memory_usage\n\n# Define input text\ninput_text = \"What is supervised machine learning?\"\n\n# Function to measure memory usage\ndef measure_memory(func):\n    mem_usage = memory_usage((func, (input_text,), {}))\n    return max(mem_usage)  # Maximum memory usage during function execution\n\n# Define the function to be executed\ndef generate_with_memory(input_text):\n    start_time = time.time()\n    outputs = gemma_lm.generate(input_text, max_length=64)\n    end_time = time.time()\n    processing_time = end_time - start_time\n    return outputs, processing_time\n\n# Obtain memory usage for one iteration\nmemory_usage_one_iteration = measure_memory(generate_with_memory)\nprint(\"Memory usage for one iteration:\", memory_usage_one_iteration, \"MB\")\n","metadata":{"papermill":{"duration":12.003086,"end_time":"2024-02-27T20:40:51.699777","exception":false,"start_time":"2024-02-27T20:40:39.696691","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-30T00:07:37.429922Z","iopub.execute_input":"2024-04-30T00:07:37.430755Z","iopub.status.idle":"2024-04-30T00:07:38.026468Z","shell.execute_reply.started":"2024-04-30T00:07:37.430711Z","shell.execute_reply":"2024-04-30T00:07:38.025196Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs, processing_time\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Obtain memory usage for one iteration\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m memory_usage_one_iteration \u001b[38;5;241m=\u001b[39m \u001b[43mmeasure_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerate_with_memory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMemory usage for one iteration:\u001b[39m\u001b[38;5;124m\"\u001b[39m, memory_usage_one_iteration, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[0;32mIn[1], line 9\u001b[0m, in \u001b[0;36mmeasure_memory\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmeasure_memory\u001b[39m(func):\n\u001b[0;32m----> 9\u001b[0m     mem_usage \u001b[38;5;241m=\u001b[39m \u001b[43mmemory_usage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(mem_usage)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/memory_profiler.py:379\u001b[0m, in \u001b[0;36mmemory_usage\u001b[0;34m(proc, interval, timeout, timestamps, include_children, multiprocess, max_usage, retval, stream, backend, max_iterations)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# When there is an exception in the \"proc\" - the (spawned) monitoring processes don't get killed.\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;66;03m# Therefore, the whole process hangs indefinitely. Here, we are ensuring that the process gets killed!\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     returned \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     parent_conn\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# finish timing\u001b[39;00m\n\u001b[1;32m    381\u001b[0m     ret \u001b[38;5;241m=\u001b[39m parent_conn\u001b[38;5;241m.\u001b[39mrecv()\n","Cell \u001b[0;32mIn[1], line 15\u001b[0m, in \u001b[0;36mgenerate_with_memory\u001b[0;34m(input_text)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_with_memory\u001b[39m(input_text):\n\u001b[1;32m     14\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 15\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mgemma_lm\u001b[49m\u001b[38;5;241m.\u001b[39mgenerate(input_text, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\n\u001b[1;32m     16\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     17\u001b[0m     processing_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n","\u001b[0;31mNameError\u001b[0m: name 'gemma_lm' is not defined"],"ename":"NameError","evalue":"name 'gemma_lm' is not defined","output_type":"error"}]}]}